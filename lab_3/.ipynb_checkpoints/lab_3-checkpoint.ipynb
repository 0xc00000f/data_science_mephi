{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ 3\n",
    "### –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ - 3 –±–∞–ª–ª–∞\n",
    "### –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ - 5 –±–∞–ª–ª–∞\n",
    "–¶–µ–ª—å —Ä–∞–±–æ—Ç—ã: —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞ —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å—è—Ö.\n",
    "\n",
    "–î–ª—è —É—Å–ø–µ—à–Ω–æ–π —Å–¥–∞—á–∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π —Ä–∞–±–æ—Ç—ã –í–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω—ã–π –∏—Å—Ö–æ–¥–Ω—ã–π –Ω–æ—É—Ç–±—É–∫, –ø—Ä–æ–¥–µ–º–æ—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–ø–∏—Å–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –ø–æ—Å–≤—è—â—ë–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é —Ç–∏–ø–∞ –æ–ø—É—Ö–æ–ª–∏ (–¥–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∏–ª–∏ –∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è).\n",
    "- id - –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "- diagnosis - –¥–∏–∞–≥–Ω–æ–∑ (M = malignant (–∑–ª–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–ø—É—Ö–æ–ª—å), B = benign (–¥–æ–±—Ä–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è)) - —è–≤–ª—è–µ—Ç—Å—è –º–µ—Ç–∫–æ–π –∫–ª–∞—Å—Å–∞ (–¥–∞–ª–µ–µ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è)\n",
    "- —Å—Ç–æ–ª–±—Ü—ã 3-33 - –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—É—Ö–æ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 1 (3 –±–∞–ª–ª–∞)\n",
    "\n",
    "### –ó–∞–¥–∞–Ω–∏–µ 1.1\n",
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç $breast\\_cancer\\_wisconsin\\_data.csv$, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –µ–≥–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ (–≤\n",
    "—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏ 7:3) –∏ –≤—ã–¥–µ–ª–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é.\n",
    "\n",
    "*–ü–æ–¥—Å–∫–∞–∑–∫–∞: –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—è –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"breast_cancer_wisconsin_data.csv\")\n",
    "\n",
    "# —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª–µ–π\n",
    "# https://stackoverflow.com/questions/43983622/remove-unnamed-columns-in-pandas-dataframe\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# TODO –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å\n",
    "\n",
    "y = data[\"diagnosis\"]\n",
    "X = data.drop(\"diagnosis\", axis=1)\n",
    "\n",
    "M, N = data.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 1.2\n",
    "–°–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ–π —ç–∫–∑–µ–º–ø–ª—è—Ä [—Ä–µ—à–∞—é—â–µ–≥–æ –¥–µ—Ä–µ–≤–∞](https://scikit-learn.org/0.20/modules/generated/sklearn.tree.DecisionTreeClassifier.html), –æ–±—É—á–∏—Ç–µ –µ–≥–æ (–ø–æ–ª—å–∑—É—è—Å—å –º–µ—Ç–æ–¥–æ–º [fit()](https://scikit-learn.org/0.20/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit)) –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é $predict\\_y$ (–º–µ—Ç–æ–¥ [predict()](https://scikit-learn.org/0.20/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'M' 'M' 'B' 'B' 'M' 'M' 'M' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B'\n",
      " 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'M' 'M'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'M' 'M' 'M' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M'\n",
      " 'M' 'B' 'M' 'B' 'B' 'M']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0, max_depth=4, min_samples_leaf=5)\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "clf.feature_importances_\n",
    "clf.score(X=X_test, y=y_test)\n",
    "\n",
    "predict_y = clf.predict(X_test)\n",
    "print(predict_y)\n",
    "\n",
    "# z = [predict_y, predict_y]\n",
    "# cnt = Counter()\n",
    "# for i in z: \n",
    "#     for i "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 1.3\n",
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –ª—é–±—ã–µ 2 –º–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏, –∏—Å–ø–æ–ª—å–∑—É—è –∏—Ö, —Å—Ä–∞–≤–Ω–∏—Ç–µ –í–∞—à–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è($predict\\_y$) —Å —Ç–µ—Å—Ç–æ–≤–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π.\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–≤–µ–¥–µ—Ç–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ 'metric_name : score'. –ù–∞–ø—Ä–∏–º–µ—Ä: $$accuracy: 0.756$$\n",
    "\n",
    "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –ø—Ä–æ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å [—Ç—É—Ç](https://habr.com/ru/company/ods/blog/328372/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision --accuracy: 0.9583333333333334\n",
      "recall --accuracy: 0.971830985915493\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def precision(y, y_hat, positive):\n",
    "    y = y.values\n",
    "    count = defaultdict(lambda:0)\n",
    "    for i in range(len(y)):\n",
    "        if (y[i] == positive) & (y_hat[i] == positive):\n",
    "            count[\"TP\"] += 1\n",
    "        if (y[i] != positive) & (y_hat[i] == positive):\n",
    "            count[\"FP\"] += 1\n",
    "    return \"precision --accuracy: \" + str(count[\"TP\"] / (count[\"TP\"] + count[\"FP\"]))\n",
    "\n",
    "def recall(y, y_hat, positive):\n",
    "    y = y.values\n",
    "    count = defaultdict(lambda:0)\n",
    "    for i in range(len(y)):\n",
    "        if (y[i] == positive) & (y_hat[i] == positive):\n",
    "            count[\"TP\"] += 1\n",
    "        if (y[i] == positive) & (y_hat[i] != positive):\n",
    "            count[\"FN\"] += 1\n",
    "    return \"recall --accuracy: \" + str(count[\"TP\"] / (count[\"TP\"] + count[\"FN\"]))\n",
    "    \n",
    "print(precision(y_test, predict_y, 'B'))\n",
    "print(recall(y_test, predict_y, 'B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 1.4\n",
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–ø–æ—Å–ª–µ –≤–∞—à–µ–π –ø—Ä–µ–¥–æ–±—Ä–∞–¥–æ—Ç–∫–∏) —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π, –ø—É—Ç—ë–º —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ $m < M$ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ $n < N$ —Å—Ç—Ä–æ–∫ (–≥–¥–µ $M$ –∏ $N$ - —á–∏—Å–ª–æ —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ —Å—Ç—Ä–æ–∫ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ). –ó–Ω–∞—á–µ–Ω–∏—è $m$ –∏ $n$ —è–≤–ª—è—é—Ç—Å—è –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ —Ñ—É–Ω–∫—Ü–∏–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ–¥–µ–º–æ—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ —Å $n=2$ –∏ $m=2$.\n",
    "\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä. –ü—É—Å—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –∏–º–µ–µ—Ç 4 —Å—Ç–æ–ª–±—Ü–∞ (**A,B,C,D**) –∏ 5 —Å—Ç—Ä–æ–∫. –¢–æ–≥–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –í–∞—à–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–∏ $m=2$ (—Å–ª—É—á–∞–π–Ω–æ –≤—ã–±—Ä–∞–ª–∏—Å—å 2 —Å—Ç–æ–ª–±—Ü–∞: **A,C** ) –∏ $n=3$ (—Å–ª—É—á–∞–π–Ω–æ –≤—ã–±—Ä–∞–ª–∏—Å—å 3 —Å—Ç—Ä–æ—á–∫–∏: 1,3,5) –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ª–µ–¥—É—é—â–∏–º:\n",
    "![](https://pp.userapi.com/c849424/v849424121/144e71/E-uOYJylgIs.jpg)\n",
    "\n",
    "–î–ª—è –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å –Ω–µ —É–¥–∞–ª—è—Ç—å —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>radius_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.07325</td>\n",
       "      <td>16.41</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.05584</td>\n",
       "      <td>14.35</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>13.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.05586</td>\n",
       "      <td>14.91</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>14.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.05586</td>\n",
       "      <td>16.22</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>14.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fractal_dimension_mean  radius_worst  symmetry_mean  radius_mean\n",
       "512                 0.07325         16.41         0.2116        13.40\n",
       "457                 0.05584         14.35         0.1619        13.21\n",
       "439                 0.05586         14.91         0.1589        14.02\n",
       "298                 0.05586         16.22         0.1635        14.26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rand_func(dataset_A, m=4, n=4, random_state=0):\n",
    "    return dataset_A[dataset_A.columns.to_series().sample(n=m, random_state=random_state)].sample(n=n, random_state=random_state)\n",
    "    \n",
    "rand_func(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 1.5\n",
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–≤–æ–π –∫–ª–∞—Å—Å –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤ (–∞–Ω—Å–∞–º–±–ª—è —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤) —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:\n",
    "- base_model_class - –∫–ª–∞—Å—Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏\n",
    "- n_base_models - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –∞–Ω—Å–∞–º–±–ª–µ\n",
    "- n_features - –∞–Ω–∞–ª–æ–≥ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ $m$ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ **rand_func** –∏–∑ –∑–∞–¥–∞–Ω–∏—è 1.4\n",
    "- n_samples - –∞–Ω–∞–ª–æ–≥ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ $n$ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ **rand_func** –∏–∑ –∑–∞–¥–∞–Ω–∏—è 1.4\n",
    "\n",
    "–î–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–ø–∏—Å–∞—Ç—å –º–µ—Ç–æ–¥—ã $train$ –∏ $predict$.\n",
    "\n",
    "–í –º–µ—Ç–æ–¥–µ $train$ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±—É—á–∏—Ç—å –≤—Å–µ *self.n_base_models* –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, —Ö—Ä–∞–Ω—è—â–∏—Ö—Å—è –≤ –º–∞—Å—Å–∏–≤–µ *self.base_models*, –Ω–∞ **—Ä–∞–∑–Ω—ã—Ö** –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞—Ö —Ä–∞–∑–º–µ—Ä–æ–º $n —Ö m$, –≥–¥–µ $m=\\sqrt{M}$, $n=\\sqrt{N}$ *(–¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥–≤—ã–±–æ—Ä–æ–∫ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é rand_func –∏–∑ –∑–∞–¥–∞–Ω–∏—è 1.4 —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ $m=\\sqrt{M}$, $n=\\sqrt{N}$ –∏ —Ä–∞–∑–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ $random\\_state$)*\n",
    "$$random\\_state=k*all*(i+1)$$–≥–¥–µ $k$- –í–∞—à –Ω–æ–º–µ—Ä –≤ —Å–ø–∏—Å–∫–µ –≥—Ä—É–ø–ø—ã, $all$-–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –≤ –í–∞—à–µ–π –≥—Ä—É–ø–ø–µ, $i$-–Ω–æ–º–µ—Ä –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –≤ –º–∞—Å—Å–∏–≤–µ *self.base_models*\n",
    "\n",
    "–í –º–µ—Ç–æ–¥–µ $predict$ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–∂–¥–æ–π –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –ø–æ–º–æ—â—å—é –ø—Ä–æ—Å—Ç–æ–≥–æ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è.\n",
    "\n",
    "–ù–∞–ø—Ä–∏–º–µ—Ä:\n",
    "–ï—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤ (predict_tree_ ) –æ—Ç–Ω–µ—Å–ª–æ —Å—Ç—Ä–æ–∫—É –∫ –∫–ª–∞—Å—Å—É 1, —Ç–æ –æ—Ç–≤–µ—Ç –∞–Ω—Å–∞–±–ª—è (predict_ensemble) –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–≤–µ–Ω 1.\n",
    "\n",
    "![](https://pp.userapi.com/c849424/v849424121/144f8c/aq28uXn5gSE.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_ensemble(object):\n",
    "    \n",
    "    def __init__(self, base_model_class, n_base_models, n_features=None, n_samples=None, **base_model_params):\n",
    "        self.base_model_class = base_model_class\n",
    "        self.n_base_models = n_base_models # —á–∏—Å–ª–æ —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "        self.n_features = n_features # —á–∏—Å–ª–æ —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ (m)\n",
    "        self.n_samples=n_samples # —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫ –≤ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ (n)\n",
    "        self.base_models = [] # –º–∞—Å—Å–∏–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π n_base_models —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "        self.features = []\n",
    "        for i in range(n_base_models):\n",
    "            self.base_models.append(base_model_class(**base_model_params)) \n",
    "        \n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Train classifier by calling .train() method of base models\n",
    "        :param X: array-like features (n_obj x n_features)\n",
    "        :param y: array-like targets\n",
    "        \"\"\"\n",
    "        i=0\n",
    "        for tree in self.base_models:\n",
    "            rs = 4*4*(i+1) #ùëüùëéùëõùëëùëúùëö_ùë†ùë°ùëéùë°ùëí=ùëò‚àóùëéùëôùëô‚àó(ùëñ+1)\n",
    "            train_X = rand_func(X, m=self.n_features, n=self.n_samples, random_state=rs)\n",
    "            self.features.append(train_X.columns)\n",
    "            train_Y = y[train_X.index.values]\n",
    "            \n",
    "            tree.fit(X=train_X, y=train_Y)\n",
    "            i+=1\n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make prediction for X using .predict() method of base models and simple voting\n",
    "        :param X: array-like features (n_obj x n_features)\n",
    "        :return results: array-like target predictions (n_obj)\n",
    "        \"\"\"\n",
    "        pred_list = []\n",
    "        for i in range(len(self.base_models)):\n",
    "            tree = self.base_models[i]\n",
    "            pred_list.append(tree.predict(X[self.features[i]]))\n",
    "        \n",
    "        import numpy as np\n",
    "        pred_np = np.vstack(pred_list).T\n",
    "        \n",
    "        print(pd.DataFrame(pred_np))\n",
    "        \n",
    "        predict_list = []       \n",
    "        for i in range(pred_np.shape[0]):\n",
    "            predict_list.append(np.unique(pred_np[i], return_counts=True)[0])\n",
    " \n",
    "        return predict_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ —Ä–∞–±–æ—Ç—É –∞–Ω—Å–∞–º–±–ª—è. –í –∫–∞—á–µ—Å—Ç–≤–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –≤–æ–∑—å–º–∏—Ç–µ [DecisionTreeClassifier](https://scikit-learn.org/0.20/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "$n\\_base\\_models=k*all$, –≥–¥–µ $k$-–≤–∞—à –Ω–æ–º–µ—Ä –≤ —Å–ø–∏—Å–∫–µ –≥—Ä—É–ø–ø—ã, $all$ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–µ–ª–æ–≤–µ–∫ –≤ –≥—Ä—É–ø–ø–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15\n",
      "0    B  B  B  B  B  M  B  B  B  B  B  B  B  B  B  B\n",
      "1    M  M  M  M  M  M  M  M  M  M  M  M  M  M  B  M\n",
      "2    M  M  B  M  M  M  B  M  M  M  M  M  M  M  M  M\n",
      "3    B  B  B  B  B  B  B  B  B  B  B  B  B  B  M  B\n",
      "4    B  B  B  B  B  B  M  B  B  B  B  B  B  B  M  B\n",
      "5    M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "6    M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "7    M  M  M  M  M  M  M  M  M  M  B  M  M  M  M  M\n",
      "8    B  M  B  M  B  B  M  B  M  B  B  B  B  B  M  B\n",
      "9    B  B  B  B  B  B  B  B  B  B  B  M  B  B  B  B\n",
      "10   B  B  B  B  B  B  B  B  B  B  M  M  B  B  B  B\n",
      "11   M  M  M  M  M  M  M  M  M  M  B  M  M  M  B  M\n",
      "12   B  B  B  B  B  B  B  M  B  B  M  M  B  M  B  B\n",
      "13   B  B  B  B  M  M  B  M  M  M  M  M  M  M  M  M\n",
      "14   B  B  B  M  B  B  M  B  B  B  B  B  B  B  B  B\n",
      "15   M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "16   B  B  B  B  B  B  B  M  B  B  B  M  B  B  B  B\n",
      "17   B  B  B  B  B  B  B  B  B  B  M  B  B  B  B  B\n",
      "18   B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B\n",
      "19   M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "20   B  B  B  M  B  B  B  B  M  B  B  M  B  M  M  B\n",
      "21   B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B\n",
      "22   M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "23   B  B  B  B  B  B  B  B  B  B  M  B  B  B  B  B\n",
      "24   B  B  B  B  B  B  M  B  B  B  M  B  B  B  B  B\n",
      "25   B  B  B  B  B  M  B  B  M  B  B  M  B  B  B  B\n",
      "26   B  B  B  B  B  B  B  B  B  B  B  M  B  B  B  B\n",
      "27   B  B  B  B  B  B  M  B  B  B  M  B  B  B  B  B\n",
      "28   B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B\n",
      "29   M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "..  .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..\n",
      "84   M  B  M  M  M  M  B  M  M  M  M  M  M  M  B  M\n",
      "85   M  M  B  M  M  M  M  M  M  B  B  M  M  M  M  M\n",
      "86   B  M  B  M  B  B  M  B  M  B  M  B  B  B  M  B\n",
      "87   M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "88   B  B  B  M  B  B  M  B  B  B  M  B  B  B  B  B\n",
      "89   B  B  B  M  B  B  B  B  B  B  B  B  B  B  B  B\n",
      "90   B  B  B  B  B  B  M  B  B  B  B  B  B  B  B  B\n",
      "91   B  B  B  M  B  B  M  B  B  B  B  M  B  B  M  B\n",
      "92   B  B  B  B  M  M  B  M  M  B  B  M  B  M  M  M\n",
      "93   B  B  B  B  B  B  B  B  B  B  M  B  B  B  B  B\n",
      "94   B  B  B  B  B  B  M  B  B  B  M  B  B  B  B  B\n",
      "95   B  B  B  B  B  M  B  B  B  B  B  B  B  B  B  B\n",
      "96   M  M  M  M  M  M  M  M  M  M  M  M  M  M  B  M\n",
      "97   M  M  B  M  M  M  M  B  M  M  M  M  B  M  M  B\n",
      "98   B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B\n",
      "99   M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "100  M  B  B  M  M  M  M  M  M  M  M  M  B  M  B  M\n",
      "101  B  B  B  B  B  B  M  B  B  B  B  B  B  B  B  B\n",
      "102  M  M  M  M  M  M  M  M  M  M  B  M  M  M  M  M\n",
      "103  M  B  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "104  B  B  B  B  B  M  B  B  B  B  M  B  B  B  B  B\n",
      "105  B  B  B  B  B  M  M  B  B  B  B  B  B  B  B  B\n",
      "106  B  B  B  B  B  B  B  B  B  B  M  B  B  B  B  B\n",
      "107  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M  M\n",
      "108  B  B  B  M  B  B  M  M  M  B  B  M  B  M  B  B\n",
      "109  B  B  B  B  B  B  B  M  B  B  B  M  B  M  B  B\n",
      "110  M  M  B  M  M  M  M  M  M  M  M  M  M  M  B  M\n",
      "111  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B  B\n",
      "112  B  B  B  B  B  M  B  M  B  B  M  M  B  B  B  B\n",
      "113  M  M  M  M  M  M  B  M  M  M  M  M  M  M  M  M\n",
      "\n",
      "[114 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import math\n",
    "n_base_models = 4*4\n",
    "n_features=int(math.sqrt(N))\n",
    "n_samples=int(math.sqrt(M))\n",
    "kwargs = {\"max_depth\":4, \"min_samples_leaf\":5}\n",
    "ensemble=my_ensemble(base_model_class=DecisionTreeClassifier, n_base_models=n_base_models, n_features=n_features, n_samples=n_samples, **kwargs)\n",
    "\n",
    "ensemble.train(X_train, y_train)\n",
    "y_hat_ens = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 1.6\n",
    "–ò—Å–ø–æ–ª—å–∑—É—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤ –∑–∞–¥–∞–Ω–∏–µ 1.3 –º–µ—Ç—Ä–∏–∫–∏, —Å—Ä–∞–≤–Ω–∏—Ç–µ —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è —Ä–µ—à–∞—é—â–∏—Ö –¥–µ—Ä–µ–≤—å–µ–≤ —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º –æ–¥–Ω–æ–≥–æ —Ä–µ—à–∞—é—â–µ–≥–æ –¥–µ—Ä–µ–≤–∞ –∏–∑ –∑–∞–¥–∞–Ω–∏—è 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision --accuracy: 0.9583333333333334\n",
      "recall --accuracy: 0.971830985915493\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_hat_ens, 'B'))\n",
    "print(recall(y_test, y_hat_ens, 'B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞–Ω–∏–µ 2 (2 –±–∞–ª–ª–∞)\n",
    "–ü–æ–ª—å–∑—É—è—Å—å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –ª–µ–∫—Ü–∏–∏, —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–≤–æ–π –∫–ª–∞—Å—Å —Ä–µ—à–∞—é—â–µ–≥–æ –¥–µ—Ä–µ–≤–∞. –ö—Ä–∏—Ç–µ—Ä–∏–π –≤–µ—Ç–≤–ª–µ–Ω–∏—è –≤—ã–±—Ä–∞—Ç—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def entropy(attribute_data):\n",
    "    \"\"\"\n",
    "    Calculate Shannon entropy\n",
    "    :param attribute_data: data from a single feature/attribute\n",
    "    :return: a float representing the Shannon entropy\n",
    "    \"\"\"\n",
    "    _, val_freqs = np.unique(attribute_data, return_counts=True)\n",
    "    # probabilities for each unique attribute value\n",
    "    val_probs = val_freqs / len(attribute_data)\n",
    "    return -val_probs.dot(np.log(val_probs))\n",
    "\n",
    "\n",
    "def info_gain(attribute_data, labels):\n",
    "    \"\"\"\n",
    "    Calculate information gain\n",
    "    :param attribute_data: data from single attribute\n",
    "    :param labels:\n",
    "    :return: a float representing information gain\n",
    "    \"\"\"\n",
    "    attr_val_counts = get_count_dict(attribute_data)\n",
    "    total_count = len(labels)\n",
    "    EA = 0.0\n",
    "    for attr_val, attr_val_count in attr_val_counts.items():\n",
    "        EA += attr_val_count * entropy(labels[attribute_data == attr_val])\n",
    "\n",
    "# Issue #1: Take entropy/information on global labels not on attribute data\n",
    "    return entropy(labels) - EA / total_count\n",
    "\n",
    "\n",
    "def get_count_dict(data):\n",
    "    \"\"\"\n",
    "    Return the unique values and their frequencies as a dictionary\n",
    "    :param data: a 1-D numpy array\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_values, data_freqs = np.unique(data, return_counts=True)\n",
    "    return dict(zip(data_values, data_freqs))\n",
    "\n",
    "\n",
    "def hypothesis_test(attribute_data, labels, p_threshold=None, return_p_value=False):\n",
    "    \"\"\"\n",
    "    Perform a chi-square test on the values for an attribute and their corresponding labels\n",
    "    :param attribute_data:\n",
    "    :param labels:\n",
    "    :param p_threshold:\n",
    "    :param return_p_value:\n",
    "    :return: True/False for p value exceeding threshold and optionally the p value tested\n",
    "    \"\"\"\n",
    "    # Get label frequencies\n",
    "    label_counts = get_count_dict(labels)\n",
    "    # Get attribute value frequencies\n",
    "    attr_val_counts = get_count_dict(attribute_data)\n",
    "    # Calculate length of data (outside of loops below)\n",
    "    total_count = len(labels)\n",
    "\n",
    "    # k and m will be used for degrees of freedom in chi-squared call\n",
    "    # k unique classes\n",
    "    k = len(label_counts)\n",
    "    # m unique attribute values\n",
    "    m = len(attr_val_counts)\n",
    "\n",
    "    statistic = 0.0\n",
    "    for attr_val, attr_val_count in attr_val_counts.items():\n",
    "        attr_val_ratio = attr_val_count / total_count\n",
    "        # Get corresponding label frequencies within this attribute value\n",
    "        label_counts_attr_val = get_count_dict(labels[attribute_data == attr_val])\n",
    "        for label_attr_val, label_count_attr_val in label_counts_attr_val.items():\n",
    "            # Expected label count is the probability of the attribute value by the\n",
    "            # probability of the label within the attribute\n",
    "            exp_label_count_attr_val = attr_val_ratio * label_counts[label_attr_val]\n",
    "            # Calculate the Chi-square statistic\n",
    "            statistic += (label_count_attr_val - exp_label_count_attr_val)**2 / exp_label_count_attr_val\n",
    "\n",
    "    # Calculate the p value from the chi-square distribution CDF\n",
    "    p_value = 1 - st.chi2.cdf(statistic, df=(m-1)*(k-1))\n",
    "\n",
    "    if return_p_value:\n",
    "        return p_value < p_threshold, p_value\n",
    "    else:\n",
    "        return p_value < p_threshold\n",
    "\n",
    "\n",
    "# Main decision tree class. There'll be one instance of the class per node.\n",
    "class DecisionTree:\n",
    "    # Main prediction at this node\n",
    "    label = None\n",
    "    # Split attribute for the children\n",
    "    attribute = None\n",
    "    # Attribute value (where attribute has been set by parent)\n",
    "    attribute_value = None\n",
    "    # A list of child nodes (DecisionTree)\n",
    "    children = None\n",
    "    # p value for hypothesis testing\n",
    "    p_value = None\n",
    "    # Threshold to test p value against\n",
    "    p_threshold = None\n",
    "    # the parent node (DecisionTree)\n",
    "    parent = None\n",
    "    # level down the tree. 1 is top level\n",
    "    level = None\n",
    "    # max depth, for pruning\n",
    "    max_level = 10000000\n",
    "\n",
    "    def __init__(self, data, labels, attributes, fitness_func=info_gain, value=None, parent=None, p_threshold=1.0, max_level=None, old_level=0):\n",
    "        \"\"\"\n",
    "        Create a Decision tree node\n",
    "        :param data: Attribute values (example inputs)\n",
    "        :param labels: example outputs\n",
    "        :param attributes: Attribute column references\n",
    "        :param fitness_func: A function to test goodness of fit\n",
    "        :param value: Value of the parent's split attribute\n",
    "        :param parent:\n",
    "        :param p_threshold: threshold for hypothesis test\n",
    "        :param max_level: maximum tree depth\n",
    "        :param old_level: parent's level in the tree\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.level = old_level + 1\n",
    "        self.p_threshold = p_threshold\n",
    "\n",
    "        if max_level is not None:\n",
    "            self.max_level = max_level\n",
    "\n",
    "        if value is not None:\n",
    "            self.attribute_value = value\n",
    "\n",
    "        if parent is not None:\n",
    "            self.parent = parent\n",
    "\n",
    "        # If data or remaining attributes are empty or we've reached max depth then set the node label to the most\n",
    "        # common one and return\n",
    "        if data.size == 0 or not attributes or self.level == self.max_level:\n",
    "            try:\n",
    "                # self.label = st.mode(labels)[0][0][0]\n",
    "                self.label = st.mode(labels)[0][0]\n",
    "            except:\n",
    "                self.label = labels[len(labels) - 1]\n",
    "            return\n",
    "\n",
    "        # If labels are all the same, set label and return\n",
    "        if np.all(labels[:] == labels[0]):\n",
    "            self.label = labels[0]\n",
    "            return\n",
    "\n",
    "        # If corresponding attribute values are the same on every example just pick the last label and return\n",
    "        # Implemented as a loop so we can stop checking as soon as we find a mismatch\n",
    "        examples_all_same = True\n",
    "        for i in range(1, data.shape[0]):\n",
    "            for j in range(data.shape[1]):\n",
    "                if data[0, j] != data[i, j]:\n",
    "                    examples_all_same = False\n",
    "                    break\n",
    "            if not examples_all_same:\n",
    "                break\n",
    "        if examples_all_same:\n",
    "            # Choose the last label\n",
    "            self.label = labels[len(labels) - 1]\n",
    "            return\n",
    "\n",
    "        # Build the tree by splitting the data and adding child trees\n",
    "        self.build(data, labels, attributes, fitness_func)\n",
    "        return\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.children is None:\n",
    "            return \"x[{0}]={1}, y={2}\".format(self.parent.attribute, self.attribute_value, self.label)\n",
    "        else:\n",
    "            if self.parent is not None:\n",
    "                return \"x[{0}]={1}, p={2}\".format(self.parent.attribute, self.attribute_value, self.p_value)\n",
    "            else:\n",
    "                return \"p={0}\".format(self.p_value)\n",
    "\n",
    "    def build(self, data, labels, attributes, fitness_func):\n",
    "        \"\"\"\n",
    "        build a subtree\n",
    "        :param data:\n",
    "        :param labels:\n",
    "        :param attributes:\n",
    "        :param fitness_func:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.choose_best_attribute(data, labels, attributes, fitness_func)\n",
    "        best_attribute_column = attributes.index(self.attribute)\n",
    "        # Attribute data is the single column with attribute values for the best attribute\n",
    "        attribute_data = data[:, best_attribute_column]\n",
    "\n",
    "        # Prune if hypothesis test fails\n",
    "        no_prune, self.p_value = hypothesis_test(attribute_data, labels, return_p_value=True, p_threshold=self.p_threshold)\n",
    "\n",
    "        if not no_prune:\n",
    "            # The try-return is probably not required here and above\n",
    "            try:\n",
    "                self.label = st.mode(labels)[0][0]\n",
    "            except:\n",
    "                self.label = labels[len(labels) - 1]\n",
    "            return\n",
    "\n",
    "        # The child trees will be passed data for all attributes except the split attribute\n",
    "        child_attributes = attributes[:]\n",
    "        child_attributes.remove(self.attribute)\n",
    "\n",
    "        self.children = []\n",
    "        for val in np.unique(attribute_data):\n",
    "            # Create children for data where the split attribute == val for each unique value for the attribute\n",
    "            child_data = np.delete(data[attribute_data == val,:], best_attribute_column,1)\n",
    "            child_labels = labels[attribute_data == val]\n",
    "            self.children.append(DecisionTree(child_data, child_labels, child_attributes, value=val, parent=self,\n",
    "                                              old_level=self.level, max_level=self.max_level))\n",
    "\n",
    "    def choose_best_attribute(self, data, labels, attributes, fitness):\n",
    "        \"\"\"\n",
    "        Choose an attribute to split the children on\n",
    "        :param data: values for all attributes\n",
    "        :param labels: values for corresponding labels\n",
    "        :param attributes: attribute columns\n",
    "        :param fitness: the closeness of fit function\n",
    "        :return: empty ... self.attribute will be set by this function instead\n",
    "        \"\"\"\n",
    "        best_gain = float('-inf')\n",
    "        for attribute in attributes:\n",
    "            attribute_data = data[:, attributes.index(attribute)]\n",
    "            gain = fitness(attribute_data, labels)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                self.attribute = attribute\n",
    "        return\n",
    "\n",
    "    def classify(self, data):\n",
    "        \"\"\"\n",
    "        Make predictions for the rows passed in data\n",
    "        :param data: rows of attribute values\n",
    "        :return: a numpy array of labels\n",
    "        \"\"\"\n",
    "        if data.size == 0:\n",
    "            return\n",
    "\n",
    "        # If we're down to one record then convert it back to a 2-D array\n",
    "        if len(data.shape) == 1:\n",
    "            data = np.reshape(data, (1,len(data)))\n",
    "\n",
    "        if self.children is None:\n",
    "            # If we're at the bottom of the tree then return the labels for all records as the tree node label\n",
    "            labels = np.ones(len(data)) * self.label\n",
    "            return labels\n",
    "\n",
    "        labels = np.zeros(len(data))\n",
    "\n",
    "        for child in self.children:\n",
    "            # Get the array indexes where the split attibute value  = child attribute value\n",
    "            child_attr_val_idx = data[:,self.attribute] == child.attribute_value\n",
    "            # pass the array subsets to child trees for classification\n",
    "            labels[child_attr_val_idx] = child.classify(data[child_attr_val_idx])\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct = 71.12299465240642\n"
     ]
    }
   ],
   "source": [
    "def read_file(filename, sep=' '):\n",
    "\n",
    "    \"\"\"\n",
    "    Read data from a text file\n",
    "    :param filename:\n",
    "    :param sep: field separation character\n",
    "    :return: 2-D list\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as input_file:\n",
    "        data = [[int(n) for n in line.rstrip('\\n').split(sep)] for line in input_file]\n",
    "    return data\n",
    "\n",
    "\n",
    "def bootstrap_replicate(data, labels):\n",
    "\n",
    "    \"\"\"\n",
    "    Sample with replacement from data\n",
    "    :param data:\n",
    "    :param labels:\n",
    "    :return: data and corresponding labels for samples (same lengths as originals)\n",
    "    \"\"\"\n",
    "\n",
    "    len_data = len(data)\n",
    "    idx = [np.random.randint(1, len_data) for _ in range(len_data)]\n",
    "\n",
    "    return data[idx], labels[idx]\n",
    "\n",
    "\n",
    "def zero_one_loss(y, y_prime):\n",
    "\n",
    "    \"\"\"\n",
    "    The zero-one loss function.\n",
    "    :param y:\n",
    "    :param y_prime:\n",
    "    :return: 0 if y = y_prime, 1 otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    return np.asarray(y != y_prime, dtype=int)\n",
    "\n",
    "\n",
    "train_data = np.array(read_file('data/spect_train.txt', sep=','))\n",
    "train_labels = train_data[:,0]\n",
    "train_data = train_data[:,1:]\n",
    "test_data = np.array(read_file('data/spect_test.txt', sep=','))\n",
    "test_labels = test_data[:,0]\n",
    "test_data = test_data[:,1:]\n",
    "\n",
    "\n",
    "# create a map of the attributes so we can retain the original column numbers as the tree splits the data\n",
    "attributes = list(range(len(train_data[0])))\n",
    "\n",
    "# Do an initial run with the full training dataset\n",
    "correct=[]\n",
    "p_max = 1.0\n",
    "level_max = 9\n",
    "tree = DecisionTree(train_data, train_labels, attributes, p_threshold=p_max, max_level=level_max)\n",
    "y = tree.classify(test_data)\n",
    "\n",
    "print(\"correct = {}\".format(sum(np.asarray(y == test_labels, dtype=int))/len(y)*100))\n",
    "\n",
    "# Do 10 runs of 25-round bootstrap training varying the depth of the trees from 1 to 10 levels\n",
    "n = 25\n",
    "num_depths = 10\n",
    "bias = np.zeros(num_depths)\n",
    "variance = np.zeros(num_depths)\n",
    "accuracy = np.zeros(num_depths)\n",
    "depths = np.arange(1,num_depths + 1)\n",
    "\n",
    "for depth in depths:\n",
    "    y = np.zeros((n, len(test_data)))\n",
    "    \n",
    "    # We are assuming that N(x) = 0, so there's no noise. This means y_star = y_t\n",
    "    y_star = t = test_labels\n",
    "    for i in range(n):\n",
    "        boot_data, boot_labels = bootstrap_replicate(train_data, train_labels)\n",
    "        tree = DecisionTree(boot_data, boot_labels, attributes, p_threshold=p_max, max_level=depth)\n",
    "        y[i] = tree.classify(test_data)\n",
    "        \n",
    "    # Under zero-one loss the main prediction is the mode (least squares: mean, absolute loss: median)\n",
    "    y_m = st.mode(y,0)[0][0]\n",
    "\n",
    "    # What's the overall test accuracy of our prediction: correct / (correct + incorrect)\n",
    "    accuracy[depth - 1] = sum(np.asarray(y_m == y_star, int)) / len(y_star)\n",
    "\n",
    "    # Bias: average zero-one loss between the optimal and main predictions\n",
    "    bias[depth - 1] = np.mean(zero_one_loss(y_star, y_m))\n",
    "\n",
    "    # Variance: average {across examples} of [(+1 if main = optimal, -1 otherwise) *\n",
    "    #           average {across test datasets} zero-one loss between individual predictions and main prediction\n",
    "\n",
    "    c2 = np.asarray(y_m == y_star, dtype=int) * 2 - 1           # 1 if y_m == y_star, -1 otherwise\n",
    "    loss_ym_y = np.array([zero_one_loss(y_m, y_i) for y_i in y])\n",
    "    variance[depth - 1] = np.mean(c2 * np.mean(loss_ym_y,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8FHX+x/HXZzebRjokIRAglIDU0AVRDAIKnggqKjb0LHg/T8/TU07Peuqd3nlnPfUOG3bs2FAsECsoHSFUqaEF0kPqZr+/P3azKSRhJWU25PN8PPLY3dnZmc9+lXnvzHznO2KMQSmllPKFzeoClFJKtR4aGkoppXymoaGUUspnGhpKKaV8pqGhlFLKZxoaSimlfKahoZRSymcaGkoppXymoaGUUspnAVYX0NQ6dOhgkpKSrC6jUQ4fPky7du2sLsNvaHvUpO1RRduipsa0x4oVKw4ZY2KPNt9xFxpJSUksX77c6jIaJS0tjdTUVKvL8BvaHjVpe1TRtqipMe0hIjt9mU8PTymllPKZhoZSSimfaWgopZTymYaGUkopn2loKKWU8pmGhlJKKZ9paCillPKZhoZHYamTf3y2kZ1Zh60uRSml/JaGhsfhUicv/bCDvy/YYHUpSinltzQ0POIjgvn9uF4sXH+AH345ZHU5SinllzQ0qrnq5O50jgrhvo/SqXAZq8tRSim/o6FRTbDDzl/O7MvG/QXMW7bL6nKUUsrvaGjUcubAjoxMiuHfn28mr7jc6nKUUsqvaGjUIiLcPaUfOUVlPPnVFqvLUUopv6KhUYcBnSO5YFgX5v6wg20HC60uRyml/IaGRj1uOaMPwQ47f/tEu+AqpVQlDY16xIYHcf1pvfhqYybfbD5odTlKKeUXNDQa8NsxSXRrH8oDn6TjrHBZXY5SSllOQ6MBQQHuLribDxTy+k/aBVcppTQ0juL0fvGc1LM9j3yxmdyiMqvLUUopS2loHIWIcNdZ/cgvLuexL7ULrlKqbdPQ8EHfhAhmjOzKK0t3sjWzwOpylFLKMhoaPvrTxN6EBtq5/2PtgquUarssDQ0RmSQim0Rkq4jcVsf7XUVksYisEpG1InKmFXUCtA8L4sbxyXy9+SCLN2ZaVYZSSlnKstAQETvwFDAZ6AdcJCL9as12J/CWMWYIMAN4umWrrGnm6CR6dGjH/Z+kU65dcJVSbZCVexojga3GmG3GmDJgHjC11jwGiPA8jwT2tmB9RwgMsHHHb/qy7eBhXl6y08pSlFLKElaGRmdgd7XXGZ5p1d0LXCoiGcAC4IaWKa1+p50QxynJHXj8y81kH9YuuEqptkWMseZmQyJyPnCGMeZqz+vLgJHGmBuqzXOzp8Z/i8ho4HlggDHGVWtZs4BZAPHx8cPmzZvXrLXvKXRx1/fFpHYJYGa/oCZffmFhIWFhYU2+3NZK26MmbY8q2hY1NaY9xo0bt8IYM/xo8wUc09KbRgbQpdrrRI48/HQVMAnAGLNERIKBDkCNM9HGmDnAHIDhw4eb1NTUZiq5yuaKdbyydCd/Pvck+nQMb9Jlp6Wl0RLfobXQ9qhJ26NKS7dFsbOYEmcJ0cHRAHyT8Q17C/dS4izBYXfgsDno2K4jYxPHAvDjvh8pd5XjsDkItAfisDmIDIqkS7h703eo+BA2sdV43ybHfgCoJdrDytBYBiSLSHdgD+4T3RfXmmcXMB6YKyJ9gWDAL0YP/OOE3sxfvZf7P07nlatGIiJWl6SU+pX2H97PgaID5JXmkVuaS25JLnabnUv6XgLAP376B8v2LyOnNIe80jxKK0rpG9OXt6a8BcDTq59mfdb6Gssc2XGkNzTuW3IfuwpqDkGUmpjKk+OfBGD6h9PJKsmq8f5vevyGh055CIDJ707GaZwE2tyB4rA7OCPpDK4eeDXGGH7/1e+90wNtgYwz45q+kWqxLDSMMU4RuR5YCNiBF4wx60XkPmC5MeZD4E/AsyJyE+6T4lcYq46n1RLdLpCbJiRz70fpfLkhk4n94q0uSak2qbyinLyyPHJKcsgtzSW/LJ/xXccDsGDbAn7Y+0NVKJTm4jIuPjn3EwAeXvYwn+/8vMby4kLivKERaA8koV0Cfdv3JSooisigSBLDEr3zPpL6CA6bg1BHKOUV5ZS7ymv8gHxs3GMUOYsoqyij3FWO0+UkKijK+/7Nw2+msKyQcpf7s+UV5fSM6ul9/+TOJ1NSUeL9fHlFOWEO9+GnClNBdkk2Za4y77rHx4xv4tY9kpV7GhhjFuA+wV192t3VnqcDY1q6Ll9dMqobr/64i799ks7Y3h0ICrBbXZJSrZYxhiJnEbmlucSFxOGwO9iUvYnlB5bX2OjnluTySOojhAWG8XHux9zw6pH9Y5ZdsozggGA25Wxi6b6lRAVFERUURe/o3kQHR2OMQUS4vP/lTO011ft+ZFAk4YFVh5tvGnZTgzV3CutU9cJx5PvJ0ckNfv7snmc3+P4do+6o970AWwDzzqp5/jYtLa3B5TUFS0OjtXPYbdz5m75c8eIyXvphB7PG9jz6h5RqQ/LL8vkl9xdyS9wb/MqN/wV9LqBTWCcW71rME6ue8AaC0+UEYP7U+fSM6snyA8t56Cf3oZrwwHCigqKIDoqm2FlMWGAYyUHJ9Brcy73RD47ybvwdNvcW/KZhNzW44R8UO6j5G+E4o6HRSKl94hjXJ5Ynv9rKuUMT6RDW9L2plLJauaucrOIsDhUfIrMokz4xfegc1pkdeTuYs3ZOjUDILc3lwVMeZGziWFYeWMkNi2ruCQTYAhjTeQydwjoRFhhGt4hupASlEBkU6d3otw9uD8DUnlOZ3H0yEYERBNiO3Fz1CelDakpqSzSB8tDQaAJ3ntWPMx79hn9/vokHz9VfLqr1cBkXmUWZHCw6SGZxJoeKDpFZnMmJHU9kZMJIdubvZOanM8kpycFQdTrx7tF3c37v8ymtKGXFgRXeDX7nsM5EBkUSFxoHuH/J/3fCf72HfqKDowkNCPUe9x/RcQQjOo6ot76wQO1O6280NJpAz9gwZo5O4sUftnPpqG707xRpdUmqjas8Zu8yLhbvWkxmsTsYDhW7Q2Fs57Fc3PdiCsoKmPjOxBqftYmNkIAQRiaMJDo4mtO6nkZsSCyxobHex67hXQHoE9OHhdMX1ltHTHAMYzr77WlJdQw0NJrIjeOTeX9VBvd9lM68WaO0C65qFuUV5WQ7s9mVv4uuEe4N95y1c9iVv8sbCIeKDnFK4in87eS/IQi3f3c7xc5i7GKnfXB7OoR2oMJUABARGME9o+8hNiSWDqEdiAuJIyY4BrvNXuN9pSppaDSRyFAHN5/eh7vmr+OzdfuZPDDB6pLUceLr3V+zdN9S1h5cS3p2Ok6Xk5FLRvL8Gc8D8On2T8kvyycuJI7OYZ0ZEjuEwXGDAfdNxF4/83Wigt0nkCvDoJKIML339Bb/Tqr10tBoQheN6MKrS3by9083MO6EOIId2gVX+a68opyN2RtZc3ANew/vZfaI2QDM2zSPZfuX0b99fy7rdxmle0uZmFJ1SOm9s99rcM+2V3SvZq9dtR0aGk0owG7j7in9uOS5H3nh++1cl6r/WNXRfbb9M17f+DrpWemUVpQC0DmsMzcOvZEgexD3j7mfyMBIHHZ3N9K0gjSGd6waIkgPhaqWpKHRxMb06sDEfvE8tWgr04cmEhcRbHVJyg84XU4252xmdeZq1hxcw5qDa3h24rN0iehCkbOIClPBhX0uJCU2hZTYFOLbVY0w0CGkg4WVK1WThkYzuOPMvkx89GseXriJh89PsbqcVsUYw57CPaRnpbMhe4N3OIfl+5fz8baPiQuNo0NIB+JC44gNiSU5OplAe6DFVR8ppyQHm9iIDIrkp30/cf2i6yl2FgPuYSpS4lIod5UDcG7yuZybfK6V5SrlMw2NZpDUoR2/HdOdZ7/dxszRSQxM1C64dTHG4DROHDYHG7M38u/l/2ZD9gbySvMACJAARiWMAmDv4b0s3r34iOsFFpyzgC4RXXh789u8veltb7fQymA5u+fZBAcEU1Re5B2FtKm5jIstOVu8exBrDq5hZ/5OZo+YzWX9LqN7ZHfOTT7XuxeR0C5BDympVktDo5lcf1ov3l2RwV8/Ws/bvxvd5jcSxhgyCjJYn72e9Kx0955E1gZuHHojF/S5gGB7MHmleUzoOoF+7fvRr30/kqOTCbIHkbYpjbN7ns3ZPc8+4srkysM44YHhdAjpwMGig6RnpZNVnIXBMK3XNACeXPUkr214jejgaO/eSnxoPPeMvgcRYXPOZkqdpcSGxtI+pH2D4ZJXmsfag2tx2B2MShhFibOECz6+AJdxERMcQ0psCuf0OofRCaMBiA2N5baRtzV/IyvVAjQ0mklEsINbzujD7e/9zMdr9zElpdPRP3ScMMawu2A36VnpRAZFMrrTaPLL8jnz/TMB9zASvaN7M7HbRHpE9gAgKTLJO9x0QyrvV9CxXcca0yclTWJS0iTva6fLSU5JjvfQ1djEsYQHhpNZlOkNnP2H93vD/JnVz/Dlri8BEITo4Gh6R/fm2dOfBeCjXz5i2f5lrDm4hm152wA4MeFERiWMItQRyuPjHqdnZE8SwxPb/A8EdXzT0GhGFwzvwstLdvLQpxuZ2C/+uO+C+9Tqp1h5YCUbsjZQUF4AwGldTmN0p9FEBkXy4CkP0iOyB8lRyd6eQM0lwBZAbGis9/XoTqMZ3Wl0vfPfMPQGpvWaVmMojSB71Thi8zbNY2f+TgZ1GMRvevyGlNgUBnYY6H0/tUtqs3wPpfyNhkYzstuEe6b0Y8acpcz5Zht/GN/wMMn+zmVc7Mrf5T28lJ6dToAEMOf0OQCsPLCSovIiJnef7D3E1CuqqtvxWT3Osqr0o+oR2cO711OXlye9jE1suheh2jwNjWY2qkd7Jg/oyDNpv3DB8C50jGw9XXB35O1ga+5WJnSbAMBt397Gp9s/BSDQFkifmD6kxFb1Dnvu9OeO241q7SuplWqrNDRawF/O7MtXGzP5x2cbefTCwVaXc1QVrgruX3o/7255F4BvLvyG6OBopvacyuiE0fRr348eUT2OOFl8vAaGUqqKhkYL6BITytUnd+fptF+YObobQ7pGW11SvZwuJ3d/fzcfbfuIy/pdxtSeU4kIjADQ0UqVUtisLqCtuG5cL2LDg7jv43T85DbndbpvyX18tO0jbhhyA7NHzKZPTB89NKOU8tLQaCFhQQHMPqMPq3bl8sHqvVaXU68pPacwe8RsZg2aZXUpSik/pKHRgs4bmsjAzpE89OlGisqcVpfjVVpRyqJdiwD3ndQu63eZxRUppfyVhkYLstmEu6f0Y39+Cf/9epvV5QBQ7Czm+q+u56a0m7wXrSmlVH00NFrYiKQYzhqUwP++/oU9ucWW1nK4/DD/9+X/8dP+n7jvpPsavE5BKaXA4tAQkUkisklEtopInYPziMgFIpIuIutF5PWWrrE53H5mXwAe+nSjZTUUlBVw7RfXsjpzNQ+e/CBTe021rBalVOthWWiIiB14CpgM9AMuEpF+teZJBm4Hxhhj+gN/bPFCm0HnqBCuHduDj9bsZfmObEtq+DbjW9Znredfp/6LM3ucaUkNSqnWx8o9jZHAVmPMNmNMGTAPqP1z9xrgKWNMDoAxJrOFa2w2v0vtSceIYP76UTouV8t1wa3s7ntmjzP5cNqH3qu9lVLKF1aGRmdgd7XXGZ5p1fUGeovI9yKyVEQmcZwIDQzgz5P78POePN5dmdEi6zxUfIhLP72U1ZmrAegS3qVF1quUOn5YeUV4XWNO1P7JHQAkA6lAIvCtiAwwxuTWWJDILGAWQHx8PGlpaU1ebHOINIYekTYe+OhnwnK3EhLgbpLCwsIm/w65zlyePPAkuRW5/LTyJ3KDc4/+IT/RHO3Rmml7VNG2qKkl2sPK0MgAqv/UTQRqX/WWASw1xpQD20VkE+4QWVZ9JmPMHGAOwPDhw01qampz1dzkonvmcM7TP/CzM4HZE04AIC0tjab8DnsL93LVwqs4LId59oxnGRo/tMmW3RKauj1aO22PKtoWNbVEe1h5eGoZkCwi3UUkEJgBfFhrnvnAOAAR6YD7cNVxdTHBkK7RnDOkM899t53d2UVNvvzMokyu+OwK8krzmDNxTqsLDKWUf7EsNIwxTuB6YCGwAXjLGLNeRO4TkbM9sy0EskQkHVgM3GqMybKm4ubz50knYBfhwU83NPmyY4JjOKnTSTx3xnMMih3U5MtXSrUtlo5ya4xZACyoNe3uas8NcLPn77jVMTKY/0vtySNfbGbptqbJxG252wgPDCc2NJZ7T7q3SZaplFJ6RbifuOaUHnSKDOa+j9JxNXIU3E3Zm7jisyv4y3d/aaLqlFLKTUPDT4QE2rntzL6k78vn24xjH8xw/aH1XLnwSgLtgdw56s4mrFAppTQ0/MqUQQkM7xbNu1vKyD5c9qs/vzpzNVd/fjXhgeHMnTSXbhHdmqFKpVRbpqHhR0SEe8/uT5ETLn52KYcKS33+rDGGh5c/TExwDC+e8SKJ4YnNWKlSqq3S0PAzAzpH8sehwezIOsxFc5aSmV/i0+dEhMfHPc6Lk14kISyhmatUSrVVGhp+aEAHOy9eMZI9ucVcOGcp+/LqH0L9uz3fcdu3t+F0OekQ0oG40LgWrFQp1dZoaPip0T3b88pVIzlUUMoF/1tS54V/i3Yt4g+L/sC23G0cLj9sQZVKqbZGQ8OPDesWw6tXn0heUTkz5ixlx6GqYFi4YyF/SvsTJ8ScwLOnP0tkUKSFlSql2goNDT+X0iWK168ZRVGZkwvnLGFrZiGfbv+U2d/MZmDsQOZMnKOBoZRqMRoarcCAzpHMmzWaCpdhxpwlOEujGJs4lv9O+C9hgWFWl6eUakM0NFqJPh3DeXBGe2wi3P1WAdf2eYBQR6jVZSml2hgNjVbi1fRXufn7y7lpahkhDjsXP7uUNbtbzz0xlFLHBw2NVuCFdS/wj2X/YHzX8UzvO5E3rx1NZKiDS577kRU7rbnHuFKqbdLQ8HP/XfNfHl3xKJOTJvPwqQ/jsDvoEhPKW9eOJjY8iMue/6nJRsZVSqmj0dDwY+sPreep1U9xds+zefCUB3HYHN73EiJDeHPWKDpFhXDFiz/x7ZaDFlaqlGorNDT8WP8O/Xn29Ge5f8z92G32I96Piwhm3qxRJLVvx1UvLWfxxkwLqlRKtSUaGn7GGMP8nPks2+++DfqohFHYpP7/TB3CgnjjmlH0jg9j1ivLWbh+f0uVqpRqgzQ0/Mz7W9/nq/yvWLJ3ic+fiW4XyGtXj6J/p0iue20lH63Z24wVKqXaMg0NP1JYVsjjKx+nR1APbhhyw6/6bGSIg1evPpFhXaO5cd4q3luZ0UxVKqXaMg0NPzJn7RyyS7I5L/o8RORXfz4sKIC5V45gVI/2/OntNby5bFczVKmUass0NPzEnsI9vLLhFab2nErXoK7HvJzQwABeuGIEY5Nj+fO7P/PKkh1NVqNSSmlo+ImEdgncd9J93Dj0xkYvK9hhZ87MYUzoG8ddH6znuW+3NUGFSillcWiIyCQR2SQiW0Xktgbmmy4iRkSGt2R9LcUYg01sTOk5hdjQ2CZZZlCAnacvGcaZAzvywCcbeDpta5MsVynVtlkWGiJiB54CJgP9gItEpF8d84UDfwB+bNkKW4bT5eSKz67g/S3vN/myAwNsPDFjCFMHd+Kfn23i0S82Y4xp8vUopdoOK/c0RgJbjTHbjDFlwDxgah3z3Q/8E/DtZtmtzHtb3mNl5kraOdo1y/ID7DYeuWAw04cl8vhXW/jnwk0aHEqpYxZg4bo7A7urvc4ATqw+g4gMAboYYz4WkVtasriWkF+Wz39W/Ydh8cOY2G1is63HbhP+ed4gAgNsPJP2C2VOF3f+pu8x9dBSSrVtVoZGXVss709gEbEBjwJXHHVBIrOAWQDx8fGkpaU1TYXN7L3s98gtzWW8bTxff/21d3phYWGzfIeJUYaD3QJ4/rvtbN+5m0v7BWJrBcHRXO3RWml7VNG2qKlF2sMYY8kfMBpYWO317cDt1V5HAoeAHZ6/EmAvMLyh5Q4bNsy0BpmHM83glwebe76/54j3Fi9e3Gzrdblc5u+fpJtuf/7YzH57jXFWuJptXU2lOdujNdL2qKJtUVNj2gNYbnzYdvu8pyEiU4A7gSBgjjHm6Ubm1TIgWUS6A3uAGcDFlW8aY/KADtXWnwbcYoxZ3sj1+oXY0FheOOMFuoR3adH1igi3TT6BoAAbTyzaSnmFi39OH0SAXXtfK6WOrt7QEJEUY8yaapMuA0bhPqy0BmhUaBhjnCJyPbAQsAMvGGPWi8h9uBPvw8Ys35+VV5TjsDsYEjfEkvWLCDef3ofAABv/+nwzpRUuHrtwMA4NDqXUUTS0p3GduM+U3m2M2Y/7pPXfABfuw0SNZoxZACyoNe3ueuZNbYp1Ws3pcjLjkxlMSprENYOusbSW609LJjDAxt8XbKTc6eLJi4cQFHDkEOxKKVWp3p+WxphrcV9H8T8RuQu4C1gE/ASc3TLlHX/e2vQWm3M20zOqp9WlADBrbE/+enZ/Pk8/wO9eWUFJeYXVJSml/FiDxyOMMWuMMVOB1cCHQIIx5kNjTGmLVHecyS3J5anVT3FiwomM6zLO6nK8Lj8pib+fM5C0zQe5+qXlFJdpcCil6lZvaIjI70RklYisBNoBk4BoEVkoIqe0WIXHkafXPE1heSGzR8z2u2skLj6xKw9PT+GHXw5xxYs/cbjUaXVJSik/1NCexnXGmCG4T37faoxxGmOewN3L6ZwWqe44kleax/yt8zm/9/n0ju5tdTl1mj4skUcvHMzynTnMfOEn8kvKrS5JKeVnGjoRvkdE7gdCgI2VE40xOcDNzV3Y8SYyKJL3zn6PMEeY1aU0aOrgzgTabdzwxirOffoHTu8Xz8DOkQxMjKRzVIjf7SEppVpWQ6ExFTgDKAe+aJlyjk95pXlEBkWSGJ5odSk+mTwwgWcddh5euIk532zD6XJfqB8d6mBA50gGdI50B0nnSBKjNUiUakvqDQ3jHkTwoxas5bhUXlHOpQsuZVTCKO4YdYfV5fhs3AlxjDshjpLyCjbuL+DnPXmsy8jj5z15PFstSKJCHQzoVDNIusRokCh1vLJy7Kk24Y2Nb7Ajfwe3jrjV6lKOSbDDzuAuUQzuEuWdVlJewabKINnjDpLnv9tGeYU7SCJDHAzoHFEjSLrGhLa6ICkuqyCzoIQD+aVkFpQQGeJgcJcowoMdVpemlGU0NJpRdkk2/13zX8Z0GsMpnY+fDmfBDjspXaJIqRYkpc4jg+SF77Z7gyQiOMAbIpWP3dpbEyRFZU53EOSXcKDA/ZjpeawMiMz8Ugrq6EEmAn3iwxnSNZqhXaMY1i2a7h3atbpAVOpYHTU0RKQnkGGMKRWRVGAQ8LIxJre5i2vtnlr1FEXOIm4dcetxv1EJCrAzKDGKQYk1g2Tz/kJ+9oTIuj15vPj9DsoqXACEBwcwoJP7JLs3SGJCsdmOra0Olzo54AmAA/klHPQ8ZlZ7zMwvpbCOMAgMsBEfEURceDB9OoZzSnIscZ7X8RFBxIYHcbCglJU7c1m5K4eP1+7ljZ92Ae5zPUO6RjOsWzRDukaRkhhFuyD9PaaOT778n/0uMFxEegHP477I73XgzOYsrLUrKi9i0e5FXNjnQr+5+rulBQXYGZjoDoVKZU4Xmw8U1AiSudWDJCiA/p0jaoRJsdPwy8FCMqvtBdQVDofruCgxKMBGfEQwceFB9O0YwdjkIO/r+Ihg4iKCiA8PJiIk4KjBfkJHOCXZfTtel8td08pdOazYmcPKXbks2pgJuO9fckLHcIZ2jWZotyiGdY3R8zzquOFLaLg8gwueAzxmjHlSRFY1d2GtXagjlA+nHbdjLh6zwACbtwfWRZ5plUGyrlqQvLx0J2VOV9UHv/y6xnKCHdXCoFMEp/aJrRkG4UHERQQTEXz0MDgWNpuQHB9Ocnw4F47oCkBuURmrdueyamcOK3bl8N7KDF5ZuhOADmGBnhCJZmjXaAYlRhLs0HG+VOvjS2iUi8hFwOXAFM80PRPYgN0Fu0lol0B4YLjVpbQK1YNkhmdaeUVVkKxYt5GTBvf3BkFcRBDhQc0TBo0RFRrIuD5xjOsTB0CFy7D5QIFnTySHVbty+Tz9AAABNqF/pwjvYa2h3aLpFBnsd99Jqdp8CY3fAr8D/maM2e65/8WrzVtW61VWUca1X1zLCTEn8EjqI1aX02o57Db6d4qkf6dI4g9vI3VIZ6tL+tXsNqFvQgR9EyK4dFQ3ALIKS1m1K5cVu3JYuTOHN5ftZu4POwCIjwhyB0jXaIZ0jWZA5wgddVj5naOGhjEmHfgDgIhEA+HGmIeau7DW6rUNr7G7YDd3nNh6rslQLad9WBAT+sUzoV884N6j2rivgJW7crznRxb8vB+AQLuNAZ0jvEEytFs08RHBVpavlE+9p9JwD4UegHu024Mi8rUxRocSqeVQ8SH+t/Z/jE0cy5jOY6wuR7UCDrvN21ng8pOSAMgsKPH20lq5M4eXluzk2W+3A9A5KoQoeykfZq729uyq/hgXEaTnSlSz8uXwVKQxJl9ErgZeNMbcIyJrm7uw1ug/q/5DqbOUW4bfYnUpqhWLCw9m0oCOTBrQEXB3FFi/N4+Vu3JZtSuH9J0H+HFbNpkFJd7rYKqLCA6o0TMs1vMYF1Gtk0B4MCGBGi7q1/MlNAJEJAG4ANBjLvUorShl7aG1XNT3IrpHdre6HHUcCQywMcRzngO6k5aWRmpqKi6XIbe4/Ijux9UvUvxxezYHC0q9XZqrC68Ml1o9zmq+DiI0UK85UVV8+b/hPtz38f7eGLNMRHoAW5q3rNYnyB7EW2e9RblLhxNXLcNmE2LaBRLTLpC+CfXPZ4wht6i8xkWOtS9+XLYjm8yC0prdnD3CgwJqXOhYGSzRoe51R4U6iA4NJDo0kPDggGO+OFO1Dr6cCH8beLva623Aec1ZVGuzKXsTncI6ER4YToBNf5Up/yIiRLcLJLpdIH061t8N3BhDXnG1cMkv5YDnYsrKiypX7MohM7+U0jrCBcAm7q7HVUF3ZkIbAAAgAElEQVTieWxXc1qUJ2QqnwcGNHgTUeVHfDkRngg8CYwBDPAdcKMxJqOZa2sVSitKuXHxjSSGJ/Lc6c9ZXY5Sx0xEPBv8QHrHNxwu+SVOcg6XkVNURm5ROTlFZeQUlR8xbU9uCev35pNTVEZJed1BAxAWFOANlSPDxeEJnUBiKt9vF0g7PSdjCV9+Fr+Ie9iQ8z2vL/VMm9hcRbUmr6S/wp7CPfz1pL9aXYpSLUJEiAxxEBniIIl2Pn+uuKzCEy41gyb3sOexqIxsz7Rd2UXkHC4jv6T+2w477EJoAMSv+roqXDx7NXXtzVQ+2vXwWaP4EhqxxpgXq72eKyJ/bK6CWpPMokzmrJ3DaV1O48SEE60uRym/FhJoJyQwhE5RIT5/xlnhIq+4vCpUDtcMnPRfdhIS2Y6conK2HzrMisO55BaVee/3UpfIEEfNvRjP3lV0qIOodu69Ge/77dzv+0M35gqXobzCRVmFizKny/3c+2goq3Cxu6D+vbmm4ktoHBKRS4E3PK8vArKaYuUiMgl4HLADz9W+aFBEbgauBpzAQeBKY8zOplh3U3h85eM4XU7tYqtUMwmw22gfFkT7sKA6309L209q6vAa04wxFJY6a+7NeAKn8nnl48HCUjYfKCS3qKzOAS8rBTts3nCJaXdk4LQLtHs26Ma7Ia/cqJdVVN/Am7o3+nV8rrzCRal3mqGigSCs1CPSxmVTjjpbo/gSGlcC/wEexX1O4wfcQ4s0iojYgadwH+bKAJaJyIeeK9ArrQKGG2OKROT/gH8CFzZ23U3B6XKSU5LDpf0upUtEF6vLUUp5iAjhwQ7Cgx10iQn1+XOlzoqqoDlcFS7uw2llZHunlbEv132eJre4HFPPtlzEfVV/YICNQLsNh+e5wy447DaCAtzTHHYboYG2atOk2rw1P+8IkCOW6fA8DwwQtm1c10StWD9fek/twn1FuJfn8NRjjVz3SGCrpzcWIjIP933JvaFhjFlcbf6luM+n+IUAWwBPT3gap6v+Y65KqdYjKMBOfIT9Vw3V4nIZ8kvKKSqrqLWBFwLsLd8jzLZ/Q/Ov4xg/1xRDiHQGdld7neGZVp+rgE+bYL2NtuLACnYXuEvXLrZKtV02m7vHWaeoEGLDg4gMcRASaLckMFrKsW7xmqL7QV3LqHNHz3NOZThwaj3vzwJmAcTHx5OWltYE5dWtzFXGA3sfINIeyZ8S/tQs6ygsLGzW79DaaHvUpO1RRduippZoj2MNjaOfkTm6DKD6yYBEYG/tmURkAu7hS041xpTWWYwxc4A5AMOHDzepqalNUF7dnlnzDDm7c3hkwiMM7zj86B84BpXDRCg3bY+atD2qaFvU1BLtUW9oiEgBdYeDAL73mavfMiDZc3+OPcAM4OJaNQwB/gdMMsZkNsE6G2X/4f28uO5FJnab2GyBoZRS/qze0DDGNOtt5zy3kL0e97hWduAFY8x6EbkPWG6M+RB4GAgD3vbc0WyXMebsehfazB5b+RgVrgr+NLx5DksppZS/s/QsrjFmAbCg1rS7qz2f0OJF1cNlXEQERnDlwCvpHNb67iKnlFJNQbv++MgmNv5y4l+sLkMppSx1/PYLa0LfZnzLygMrrS5DKaUsp6FxFEXlRdy75F4eXvYwpr5LP5VSqo3Q0DiKF9a9QGZRJrNHzsZzMl4ppdosDY0G7C3cy9z1c5mcNJkhcUOsLkcppSynodGAR1Y8giDcNOwmq0tRSim/oL2n6mGMYWCHgfRv35+EsAZuwKyUUm2IhkY9RITL+19udRlKKeVX9PBUHT7f8Tkf/fKR9pZSSqladE+jlsPlh3nwpwfpFNaJs3qcZXU5Sil/VXYY8vdB/h4oyQWbA+yevwafB3qeB1R7bv3tZH2loVHLcz8/x6HiQzwx7gntYqtUW2SMOwTy90H+Xnco5O+Fgr2e155pJXlNuFKpJ0x8eF4tmLrl24HUJqzrSBoa1WQUZPDy+peZ0mMKA2MHWl2OUqqpuVxQdKjmxj9/LxTsq3qevxfKi2p9UCAsDiI6QUwP6DbG/Tyis/sxJApcTqhwgqscKspqPS/3vF/H84pyz3wNPS878vPlRUcsK9zesdmbUEOjmkdWPILdZufGoTdaXYpSLcMYMC5wVYCpqPVYa7rLWW2ay31IxWZ3/+oVz6MtoGqardq0lthrr3BC4f6qQ0Z1hsI+94a4OlsAhCe4N/4dB0LyGZ5AqAyFBAjrCAGBzf8dGmldWloz72doaNRwZvczGZUwivh28VaXopR7g16wDw5thkNb3I9ZWxlycC9sCau2Mfdhg28q3L+yawSAZ76WILZqAWKvGSi2ALDZar32JYzsDMjMhC33uYOh8MCR3ycguGrj33W0Jxw61wyFdrHu9SufaGhUM6Gb34zErtoSZylkb/OEQ7WAOLQFygqr5gsMhw69qLAHQXCke+NZuQEWW7XXAXVMq2/eykdbHfPZqzbmR7wn7lBzOav9VQukyj9Tx7Qj5qsWYrWnVZ/fWQquwzWWG1xyGKJ6QlxfCO9U85BRRCcIiW6ZvZw2RENDqZZSlF0tGKqFQ86Omr+QIxKhQzIMvgRie0MHz19YPIiwVm9x6rVc26LFaWgo1ZRcFZC7s9reQrVwKMqqms8eBO17QcdBMGC6JxiS3dOCwqyrX6mj0NBQ6liUFkLWliPDIesXqCitmi+0gzsQTjirao+hQzJEdW1VffOVqqShofxXSR5kbyc6exVscQKenj6VPX6M68hpGM9zU+v92vNUf00979eaVnCgKhzyM6rqFBtEd3cHQq8JNcMhNKaFG02p5qWhoaxjDBRmuk8C52yH7O01Hz2Hc1IA1lpaqVtgmDsIksa4HyvDIaYHBARZXZ1SLUJDQzWvCifk7faEwTZPIOyoeiw/XDWv2CAy0f2rve8U92NMd1Zu2cvQocPc7yPu3jAi7tfeabaqaTVey5Hv1/sZqWMZtqplBARpTxzV5mloqMYrK3IHQOVeQvU9h7zd7i6SlexBENPdHQg9TvUGA9Hd3cf567iAKj8zDbqMbLGvo5Sqn6WhISKTgMcBO/CcMeahWu8HAS8Dw4As4EJjzI6WrrPNMwaKc2oePqoeDIX7a84fHOk+ZNNpCAw4t2YwhCfohVRKtWKWhYaI2IGngIlABrBMRD40xqRXm+0qIMcY00tEZgD/AC5s+WrbEGcZ7FsDu36Avas8h5R2QGmtwdnCE9wh0GsCxCTVDAY9+avUccvKPY2RwFZjzDYAEZkHTAWqh8ZU4F7P83eA/4iIGL3RRdMpyYPdy2DXEti1FPYsB2eJ+72obu7rBhJHuPccKoMhqhsEhlpbt1LKElaGRmdgd7XXGcCJ9c1jjHGKSB7QHjjUIhUej/L3ugNipyckDqwDjHt4iIQUGH4VdBsNXUZBWKzV1Sql/IyVoVFXN5TaexC+zIOIzAJmAcTHx5OWltbo4qxUWFjYNN/BuAgtyiAyL53IvA1E5qUTUpIJQIUtmLzIE8hLmkFeZD/yI3rjsge7P3cAOLC+8etvIk3WHscJbY8q2hY1tUR7WBkaGUCXaq8Tgb31zJMhIgFAJJBde0HGmDnAHIDhw4eb1j4WTdqxjqfjLIW9q6sONe1e6j6BDdAuDnqMdo/02XUU9viBxNgDaA1nH465PY5T2h5VtC1qaon2sDI0lgHJItId2APMAC6uNc+HwOXAEmA6sEjPZ1RTnAsZy6oON+1ZUTWERftk99AVnpAgpodeY6CUajTLQsNzjuJ6YCHuLrcvGGPWi8h9wHJjzIfA88ArIrIV9x7GDKvq9Qt5Ge49iMo9iQPrAeMeujohBUZe4w6JLifq+QilVLOw9DoNY8wCYEGtaXdXe14CnN/SdfkFlwsObqwKiF1LIW+X+73AMHePpnF/ce9FdB4Gge2srVcp1SboFeH+pmA//dc9CEtnVt24PizevQcx+vfukIgfAHb9T6eUanm65fEnrgp492pislfB4AurzkdEd9fzEUopv6Ch4U++fxx2fMuWPjdwwtkPWF2NUkodQQcB8hcZK2Dx36D/OezvON7qapRSqk4aGv6gJB/evRLCO8FZj+mhKKWU39LDU/5gwS2Quwt++ymERFldjVJ+q7y8nIyMDEpK3OOjRUZGsmHDBour8h++tEdwcDCJiYk4HI5jWoeGhtXWvAlr34TU290nvZVS9crIyCA8PJykpCREhIKCAsLDw60uy28crT2MMWRlZZGRkUH37t2PaR16eMpK2dvgkz+5e0mdcovV1Sjl90pKSmjfvj2ih3CPiYjQvn17757asdDQsEpFObx7tfuGROc+q9ddKOUjDYzGaWz7aWhYZfHf3WNFTXkCorocfX6llF+w2+0MHjyYlJQUhg4dyg8//ADA3r17mT59usXVNT/9eWuFbV/Dd4/C0JnQf5rV1SilfoWQkBBWr14NwMKFC7n99tv5+uuv6dSpE++8847F1TU/3dNoaYez4P1r3XfEm/TQ0edXSvmt/Px8oqOjAdixYwcDBgzwPj/llFMYOnRojb2Rffv2MXbsWAYPHsyAAQP49ttvLav9WOmeRksyBj68Hoqy4OI3dZBBpRrhrx+t5+fdOdjt9iZbZr9OEdwzpX+D8xQXFzN48GBKSkrYt28fixYtOmKeuLg4vvjiC4KDg9myZQsXXXQRy5cv5/XXX+eMM87gjjvuoKKigqKioiarvaVoaLSk5c/DpgVwxt/dQ5krpVqd6oenlixZwsyZM1m3bl2NecrLy7n++utZvXo1drudzZs3AzBixAiuvPJKysvLmTZtGoMHD27x+htLQ6OlHEiHhXdArwlw4v9ZXY1Srd49U/pbfp3G6NGjOXToEAcPHqwx/dFHHyU+Pp41a9bgcrkIDnbfSnns2LF88803fPLJJ1x22WXceuutzJw504rSj5me02gJ5cXw7lUQFAHTnnF3s1VKtXobN26koqKC9u3b15iel5dHQkICNpuNV155hYqKCgB27txJXFwc11xzDVdddRUrV660ouxG0T2NlvD5XZCZDpe+C2FxVlejlGqEynMa4L7C+qWXXjrivMp1113Heeedx9tvv824ceNo1859/jItLY2HH34Yh8NBWFgYL7/8covX31gaGs1t4wJY9iyMvt59aEop1apV7jXUlpSU5D23kZyczNq1a73vPfjggwBcfvnlXH755c1fZDPS4yTNKX8vfPB76DgIxt999PmVUsrPaWg0F5fLfT2GswSmvwABQVZXpJRSjaaHp5rLD4/D9m/g7CehQ7LV1SilVJPQPY3mkLECFj0A/abBkMusrkYppZqMhkZTKy1wd68NT4Apj+td+JRSxxVLQkNEYkTkCxHZ4nmMrmOewSKyRETWi8haEbnQilp/tU9ugdyd7uHO9S58SqnjjFV7GrcBXxljkoGvPK9rKwJmGmP6A5OAx0TEv7fCa9+CtfNg7GzoNtrqapRSTSw1NZWFCxfWmPbYY49x3XXX+byMM888k9zc3KYurcVYFRpTgZc8z18Cjhgf3Biz2RizxfN8L5AJxLZYhb9W9nb4+GboMgrG3mp1NUqpZnDRRRcxb968GtPmzZvHRRdddNTPGmNwuVwsWLCAqCj//v3bEKtCI94Ysw/A89jgZdIiMhIIBH5pgdp+vcq78IkNztO78Cl1vJo+fToff/wxpaWlgHsI9L179zJ48GDGjx/P0KFDGThwIB988IH3/b59+3LdddcxdOhQdu/eTVJSEocOHQJg2rRpDBs2jP79+zNnzhzvesLCwrjjjjtISUlh1KhRHDhwAIADBw5wzjnnkJKSQkpKinfI9VdffZWRI0cyZswYrr322novQGwKYoxpngWLfAl0rOOtO4CXjDFR1ebNMcYccV7D814CkAZcboxZWs88s4BZAPHx8cNq/xJobt23vUK3Xe+wvt9sDsaNafTyCgsLCQsLa4LKjg/aHjW15faIjIykV69eAAQtvgfbgfXQhH1NXHH9KR331wbnmT59Or/97W/5zW9+wyOPPEJ2djb33nsvRUVFREREkJWVxWmnncbq1avZtWsXgwYN4osvvmDkyJEADBgwgK+//pr27duTnZ1NTEwMxcXFpKamsmDBAtq3b09ERARvvvkmkydP5q677iI8PJzZs2dzxRVXMGLECH7/+99TUVFBYWEh+/fv56677uK1117DZrNxyy23MGLECC6++OJ6v8PWrVvJy8urMW3cuHErjDHDj9ZGzfaT2BhT75gZInJARBKMMfs8oZBZz3wRwCfAnfUFhmddc4A5AMOHDzepqamNqv1X2f4NpL0LQy6j/9Q7mmSRaWlptOh38HPaHjW15fbYsGFD1ai2jkCcAgFNuWfvCCTwKKPmXnbZZXzwwQfMmDGD999/nxdeeIGwsDDuuusuvvnmG2w2G/v27aOoqIiwsDC6devG+PHjvZ8XEcLCwggPD+ff//4377//PgB79uxh//79JCUlERgYyPnnn4+IMHr0aL744gvCw8P55ptveP311wkKcl8sHBUVxfz581mzZg2nnXYaLpeL0tJSEhMTGxz9Nzg4mCFDhhxTE1l1HOVD4HLgIc/jB7VnEJFA4H3gZWPM2y1bno+KsuG9a6F9T5j8D6urUaptmfwQxRYMjT5t2jRuvvlmVq5cSXFxMUOHDmXu3LkcPHiQFStW4HA4SEpKoqSkBMA7WGFtaWlpfPnllyxZsoTQ0FBSU1O9n3E4HIinu77dbsfpdNZbjzGGyy+/nAcffLBFhoq36pzGQ8BEEdkCTPS8RkSGi8hznnkuAMYCV4jIas+f/9yxxBj44Ho4fBDOe17vwqdUGxEWFkZqaipXXnml9wR4Xl4ecXFxOBwOFi9ezM6dO4+6nLy8PKKjowkNDWXjxo0sXVrvwRSv8ePH88wzzwDugRPz8/MZP34877zzDpmZ7gM22dnZPq3/WFkSGsaYLGPMeGNMsucx2zN9uTHmas/zV40xDmPM4Gp/q62ot07LX4BNn8CEe6GT/2SZUqr5XXTRRaxZs4YZM2YAcMkll7B8+XKGDx/Oa6+9xgknnHDUZUyaNAmn08mgQYO46667GDVq1FE/8/jjj7N48WIGDhzIsGHDWL9+Pf369eOBBx7g9NNPZ/To0UycOJF9+/Y1+jvWp9lOhFtl+PDhZvny5c27kswNMCcVuo2BS95p8psqteVj1nXR9qipLbfHhg0b6Nu3r/e11Xfu8ze+tkftdgQQEZ9OhOswIr9WeQm8cxUEhcM5/9W78Cml2hS9oODX+uIuyFwPl+hd+JRSbY/+TP41Nn0KP82BUddBst6FTynV9mho+Cp/H8y/DjoOdJ/8VkqpNkhDwxcuF8z/nfsufOfpXfiUUm2XntPwxQ9PwLY0mPIExPa2uhqllLKM7mkczZ4VsOh+6DcVhs60uhqllB94//33ERE2btxodSktTkOjIaUF7u61YR31LnxKKa833niDk08++Yhh0ptSc45U2xgaGg1ZcKv7LnznPQshdQ7Cq5RqYwoLC/n+++95/vnna4TGP//5TwYOHEhKSgq33ea+r9zWrVuZMGECKSkpDB06lF9++YW0tDTOOuss7+euv/565s6dC0BSUhL33XcfJ598Mm+//TbPPvssI0aMICUlhfPOO4+ioiKg7iHS77rrLp5++mnvcu+44w6eeOKJJv/+ek6jPmvfhjVvwKl/hm4nWV2NUqoOv//m99jt9hrTzkg6gxknzKDYWcx1Xx55R72pvaYyrdc0ckpyuDnt5hrvvTjpxaOuc/78+UyaNInevXsTExPDypUrOXDgAPPnz+fHH38kNDSU7OxswD28yG233cY555xDSUkJLpeL3bt3N7j84OBgvvvuOwCysrK45pprALjzzjt5/vnnueGGG/jDH/7Aqaeeyvvvv+8dIr1Tp05MmzaNP//5z7hcLubNm8dPP/101O/za2lo1CVnB3xSeRe+2VZXo5TyI2+88QZ//OMfAZgxYwZvvPEGLpeL3/72t4SGhgIQExNDQUEBe/bs4ZxzzgHcYeCLCy+80Pt83bp13HnnneTm5lJYWMgZZ5wBwKJFi3j55ZcB9yi4kZGRREZGEhMTw6pVqzhw4ABDhgyhffv2Tfa9K2lo1FZ5Fz5E78KnlJ97auxT9Y61FBIQ0uCeQ3RwtE97FtVlZWWxaNEi1q1bh4hQUVGBiHDeeed5hzKvVN+4fgEBAbhcLu/ryuHQK1UfSv2KK65g/vz5pKSkMHfuXNLS0hqsb+bMmcydO5f9+/dz5ZVX/qrv5is9p1Fb2kOQsQymPAZRXa2uRinlR9555x1mzpzJzp072bFjB7t376Z79+7ExMTwwgsveM85ZGdnExERQWJiIvPnzwegtLSUoqIiunXrRnp6OqWlpeTl5fHVV1/Vu76CggISEhIoLy/ntdde806va4h0gClTpvDZZ5+xbNky715JU9PQqG77t/Dtv2HIpTDgXKurUUr5mTfeeMN7uKnSeeedx969ezn77LMZPnw4gwcP5l//+hcAr7zyCk888QSDBg3ipJNOYv/+/XTp0oULLriAQYMGcckllzR4B73777+fE088kYkTJ9YYbr2uIdIBAgMDGTduHBdccMER53qaig6NXqkoG54ZA4GhMOtrCLLuHsxteejrumh71NSW20OHRm9YXl4ep556Km+//TbJycn1zqdDozcF44KEFPdd+CwMDKWUOhbp6ekMHjyY8ePHNxgYjaVneSu16wAXN9+FOkop1Zz69evH2rVrj9t7hCullGqFNDSUUq3K8XYetqU1tv00NJRSrUZwcDBZWVkaHMfIGENWVpbPFxrWRc9pKKVajcTERDIyMjh48CDgvjCuMRvA440v7REcHExiYuIxr8OS0BCRGOBNIAnYAVxgjMmpZ94IYAPwvjHm+paqUSnlfxwOB927d/e+TktLa/A6h7amJdrDqsNTtwFfGWOSga88r+tzP/B1i1SllFKqQVaFxlTgJc/zl4Bpdc0kIsOAeODzFqpLKaVUA6wKjXhjzD4Az2Nc7RlExAb8G7i1hWtTSilVj2Y7pyEiXwId63jrDh8XcR2wwBizu/bokXWsaxYwy/OyUEQ2+Vyof+oAHLK6CD+i7VGTtkcVbYuaGtMe3XyZyZKxpzwb9VRjzD4RSQDSjDF9as3zGnAK4ALCgEDgaWNMQ+c/jgsistyXMWDaCm2PmrQ9qmhb1NQS7WFVl9sPgcuBhzyPH9SewRhzSeVzEbkCGN4WAkMppfyZVec0HgImisgWYKLnNSIyXESes6gmpZRSR2HJnoYxJgsYX8f05cDVdUyfC8xt9sL8xxyrC/Az2h41aXtU0baoqdnb47i7n4ZSSqnmo2NPKaWU8pmGhh8RkS4islhENojIehG50eqarCYidhFZJSIfW12L1UQkSkTeEZGNnv9HRltdk5VE5CbPv5N1IvKGiLSpQahE5AURyRSRddWmxYjIFyKyxfMY3dTr1dDwL07gT8aYvsAo4Pci0s/imqx2I+6xxxQ8DnxmjDkBSKENt4uIdAb+gLtX5QDADsywtqoWNxeYVGvarxmi6ZhoaPgRY8w+Y8xKz/MC3BuFztZWZR0RSQR+A7T5HnWegTvHAs8DGGPKjDG51lZluQAgREQCgFBgr8X1tChjzDdAdq3JPg3R1BgaGn5KRJKAIcCP1lZiqceA2bgv8GzregAHgRc9h+ueE5F2VhdlFWPMHuBfwC5gH5BnjNEx6nwYoqmxNDT8kIiEAe8CfzTG5FtdjxVE5Cwg0xizwupa/EQAMBR4xhgzBDhMMxx6aC08x+qnAt2BTkA7EbnU2qraBg0NPyMiDtyB8Zox5j2r67HQGOBsEdkBzANOE5FXrS3JUhlAhjGmcs/zHdwh0lZNALYbYw4aY8qB94CTLK7JHxzwDM2E5zGzqVegoeFHxD0y4/PABmPMI1bXYyVjzO3GmERjTBLuE5yLjDFt9pekMWY/sFtEKsdoGw+kW1iS1XYBo0Qk1PPvZjxtuGNANZVDNEE9QzQ1lt7u1b+MAS4DfhaR1Z5pfzHGLLCwJuU/bgBeE5FAYBvwW4vrsYwx5kcReQdYibvX4Sra2NXhIvIGkAp0EJEM4B7cQzK9JSJX4Q7W85t8vXpFuFJKKV/p4SmllFI+09BQSinlMw0NpZRSPtPQUEop5TMNDaWUUj7T0FBtnoi0F5HVnr/9IrKn2uvAZlpngIgc89hRInJz5aiujV2WUr+GdrlVqhoRuRcoNMb8q9Z0wf3vpUnGwfIMsnfIGBN1jJ/PAAYYY3Ibuyylfg3d01CqHiLSy3Ovhv/ivogsQUQmi8gSEVkpIm9WDhooIiNE5GsRWSEin4pIfB3L6ykiP4rIMuDeWu/dJiI/ichaEbm72vrXi8grIvKziLwlIiEichPugei+FZEvqy3jIRFZ46mvyQeqUwo0NJQ6mn7A855BAstxDxI43hgzFFgL3CgiQbjvdXGeMWYY8Cpwfx3LehJ43BgzAveItQCIyJlAV+BEYDBwkohUjqPUD3jKGDMQKAGuNcY8intMoVOMMRM880UCXxtjUoAlwJVN1gJKVaPDiCjVsF+MMcs8z0/CvRH/wX20ikDgO6Av0B/40jPdjnuAwdpGA1M8z18B/up5fjowGfdQGABhQG/cwbDdGLPUM/1VYBbuIeNrKzbGfOp5vgI45Vd9S6V8pKGhVMMOV3suuO+cd1n1GURkCLDWGHO0DbXx/NUmwAPGmOdrLbdXHfPXdxKyrNrzCvTftmomenhKKd/9AJwqIj0ARKSdiCTjHm22s4iM9EwPFJH+dXx+KXCB5/kl1aYvBK6qdn4kUUQ6eN7rLiIjPM8vwr1nA1AAhDfR91LKZxoaSvnIGHMAuAp4U0TW4A6R3saYUmA68Ihn+irc5ydq+wNwk4j8hPsQVOVyF+C+P8ZSEfkZeKva++uBa0RkLdCOqpFc5+A+HOY9Ea5US5ERrbUAAABNSURBVNAut0r5Kc/hqXeMMYOtrkWpSrqnoZRSyme6p6GUUspnuqehlFLKZxoaSimlfKahoZRSymcaGkoppXymoaGUUspnGhpKKaV89v/bO5poZIzFwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Bias, Variance and overall accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(depths, bias)\n",
    "plt.plot(depths, variance)\n",
    "plt.plot(depths, accuracy, ls='--')\n",
    "plt.legend([\"Bias\", \"Variance\", \"Accuracy\"])\n",
    "plt.xlabel('Tree depth')\n",
    "plt.ylabel('Loss %')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
